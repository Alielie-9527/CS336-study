{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41664d05",
   "metadata": {},
   "source": [
    "### 第一步通过三元组构建知识图谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 加载多语言句子嵌入模型,用于生成句子的嵌入向量，方便后续的相似度检查\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')  \n",
    "\n",
    "DATA_PATH = './data/harry.json'\n",
    "\n",
    "# 第一部分构建Graph类\n",
    "class Knowledgebase:\n",
    "    def __init__(self,data_path=DATA_PATH):\n",
    "        self.graph = defaultdict(list)\n",
    "        self.nodes = set()\n",
    "        self.embeddings = {}\n",
    "        self.node_attributes = defaultdict(dict)\n",
    "        self.community_labels = {} # 可以在后续进行社区检测完后填充\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "        self._build_graph_from_json(raw_data)\n",
    "\n",
    "        # 生成节点向量，这样可以基于相似度优化查询过程\n",
    "        node_list = list(self.nodes)\n",
    "        embeddings = model.encode(node_list, show_progress_bar=True)\n",
    "        for node, emb in zip(node_list,embeddings):\n",
    "            self.embeddings[node] = emb\n",
    "\n",
    "\n",
    "    def _build_graph_from_json(self,raw_data):\n",
    "        '''\n",
    "        将json解析为图结构，同时添加反向边以构建无向图（或双向图）\n",
    "        '''\n",
    "        # key 是人物名称，value是属性字典\n",
    "        for name, info in raw_data.items():\n",
    "            self.nodes.add(name)\n",
    "            # 然后对属性进行处理\n",
    "            attributes = ['出生', '血统', '婚姻状况', '物种', '性别', '职业', '从属']\n",
    "            for attr in attributes:\n",
    "                if attr in info:\n",
    "                    # 在节点属性中存放各种属性\n",
    "                    self.node_attributes[name][attr] = info[attr]\n",
    "            \n",
    "            # 处理家庭信息，建立图的边的关系\n",
    "            if '家庭信息' in info:\n",
    "                for relation, relatives in info['家庭信息'].items():\n",
    "                    if isinstance(relatives, str):\n",
    "                        relatives = [relatives]\n",
    "                    for relative in relatives:\n",
    "                        # 正向边: name -> relative\n",
    "                        self.graph[name].append((relation, relative))\n",
    "                        # 反向边: relative -> name (添加前缀 ~ 表示反向)\n",
    "                        self.graph[relative].append((\"~\" + relation, name))\n",
    "                        \n",
    "                        self.nodes.add(relative)\n",
    "            \n",
    "            # 处理职业关系、从属关系\n",
    "            for key in ['职业','从属']:\n",
    "                if key in info:\n",
    "                    relations = info[key]\n",
    "                    if isinstance(relations, str):\n",
    "                        relations = [relations]\n",
    "                    for relation in relations:\n",
    "                        # 正向边\n",
    "                        self.graph[name].append((key, relation))\n",
    "                        # 反向边 (例如: 霍格沃茨 -> 哈利)\n",
    "                        self.graph[relation].append((\"~\" + key, name))\n",
    "                        \n",
    "                        \n",
    "                        self.nodes.add(relation)        \n",
    "    \n",
    "    def get_neighbors(self, node):\n",
    "        return self.graph.get(node, [])\n",
    "\n",
    "    def get_embedding(self, node):\n",
    "        return self.embeddings.get(node, None)\n",
    "\n",
    "    def get_all_nodes(self):\n",
    "        return list(self.nodes)\n",
    "    \n",
    "    def get_undirected_neighbors(self):\n",
    "        # 获取无向图 (用于社区发现)\n",
    "        # 由于我们现在 graph 本身就是双向的，这里逻辑依然适用，只是会有重复边，set会自动去重\n",
    "        undirected = defaultdict(set)\n",
    "        for head,edges in self.graph.items():\n",
    "            for relation,tail in edges:\n",
    "                undirected[head].add(tail)\n",
    "                undirected[tail].add(head)\n",
    "        return undirected\n",
    "    \n",
    "    def _compute_degrees(self,undirected):\n",
    "        degrees = {}\n",
    "        for node, neighbors in undirected.items():\n",
    "            degrees[node] = len(neighbors)\n",
    "        return degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c1e56c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 45/45 [00:00<00:00, 140.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 中文图谱构建成功！\n",
      "总节点数: 1437\n",
      "\n",
      "[乔治·韦斯莱] 的关系网示例:\n",
      "  --[罗恩·韦斯莱]--> ~哥哥\n",
      "  --[塞普蒂默斯·韦斯莱]--> 祖父\n",
      "  --[塞德瑞拉·布莱克]--> 祖母\n",
      "  --[普威特先生]--> 外祖父\n",
      "  --[普威特夫人]--> 外祖母\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 测试部分 ---\n",
    "DATA_PATH = './data/harry.json'\n",
    "if __name__ == \"__main__\":\n",
    "    kb = Knowledgebase(DATA_PATH)\n",
    "    print(f\"\\n✅ 中文图谱构建成功！\")\n",
    "    print(f\"总节点数: {len(kb.nodes)}\")\n",
    "    \n",
    "    test_node = \"乔治·韦斯莱\"\n",
    "    if test_node in kb.nodes:\n",
    "        print(f\"\\n[{test_node}] 的关系网示例:\")\n",
    "        # 打印前5个邻居\n",
    "        for neighbor, relation in kb.get_neighbors(test_node)[:5]:\n",
    "            print(f\"  --[{relation}]--> {neighbor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7a711",
   "metadata": {},
   "source": [
    "### 通过LPA算法进行社区划分\n",
    "在第一版中，我采取了以下步骤：\n",
    "1. 初始化每个节点的标签为其自身。\n",
    "2. 迭代更新每个节点的标签为其邻居中出现频率最高的标签。\n",
    "3. 重复上述过程直到标签不再变化或达到最大迭代次数。\n",
    "\n",
    "但是该方法处理结果并不理想，社区划分效果较差。最后发现应该是数据集的原因，换了数据集发现效果还不错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fe686fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPA算法实现社区发现\n",
    "# 初始化标签，每个节点的标签初始为其自身\n",
    "def init_labels(nodes):\n",
    "    labels= {node: node for node in nodes}\n",
    "    return labels\n",
    "\n",
    "\n",
    "# LPA算法核心步骤： 投票更新标签\n",
    "def LPA_step(node,graph, labels):\n",
    "    '''\n",
    "    输入：\n",
    "        node: 当前要更新的节点\n",
    "        graph： 图\n",
    "        labels: 当前节点标签字典\n",
    "    '''\n",
    "    neighbors = graph.get(node, [])\n",
    "    if not neighbors:\n",
    "        return labels[node] #  没有邻居，标签不变\n",
    "\n",
    "    label_count = defaultdict(int)\n",
    "    for relation,neighbor in neighbors:\n",
    "        neighbor_label = labels.get(neighbor, None)\n",
    "        label_count[neighbor_label] += 1\n",
    "\n",
    "    # 选择出现频率最高的标签\n",
    "    max_count =max(label_count.values())\n",
    "    best_labels = [label for label, count in label_count.items() if count == max_count]\n",
    "\n",
    "    # 如果有多个标签频率相同，随机选择一个\n",
    "    new_label = np.random.choice(best_labels)\n",
    "    return new_label\n",
    "\n",
    "# 运行LPA算法直到收敛或者最大迭代次数\n",
    "def LPA(graph, max_iterations=100,all_nodes=None):\n",
    "    # 初始化标签 {node: label}\n",
    "    # 修正点1：初始化时应该使用 all_nodes，而不是 graph.keys()\n",
    "    # graph.keys() 只包含作为起点的节点，可能会漏掉只作为终点的节点\n",
    "    labels = init_labels(all_nodes)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        prev_labels = labels.copy()\n",
    "        \n",
    "        #打乱节点更新顺序\n",
    "        # LPA 算法对更新顺序敏感，随机打乱可以避免陷入局部最优，并加速收敛\n",
    "        np.random.shuffle(all_nodes)\n",
    "        \n",
    "        for node in all_nodes:\n",
    "            labels[node] = LPA_step(node, graph, labels)\n",
    "        # 检查是否收敛\n",
    "        if labels == prev_labels:\n",
    "            print(f\"算法在第 {iteration} 次迭代后收敛。\")\n",
    "            break\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7031f",
   "metadata": {},
   "source": [
    "### SLPA 算法改进\n",
    "SLPA算法是对LPA算法的改进，由于在作业过程中，LPA算法和Louvain算法都是每个节点只能属于一个社区，但是对于当前数据集复杂的人物关系，这种划分会导致有些关系密切的反而检查不到，比如同属于一个学院的两个人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13cdca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLPA (Speaker-Listener Label Propagation Algorithm) 实现重叠社区发现\n",
    "def SLPA(graph, T=20, threshold=0.1, all_nodes=None):\n",
    "    '''\n",
    "    SLPA 算法：允许重叠社区发现\n",
    "    :param graph: 图结构\n",
    "    :param T: 迭代次数\n",
    "    :param threshold: 概率阈值，超过该概率的标签会被保留\n",
    "    :param all_nodes: 所有节点列表\n",
    "    '''\n",
    "    # 每个节点记忆的标签中最开始只包含自己\n",
    "    memory = {node: [node] for node in all_nodes}\n",
    "    \n",
    "    for t in range(T):\n",
    "        # 随机顺序遍历节点（作为 Listener）\n",
    "        np.random.shuffle(all_nodes)\n",
    "        \n",
    "        for listener in all_nodes:\n",
    "            neighbors = graph.get(listener, [])\n",
    "            if not neighbors:\n",
    "                continue\n",
    "            \n",
    "            #  每个邻居 (Speaker) 随机从自己的内存中说出一个标签\n",
    "            spoken_labels = []\n",
    "            for relation, speaker in neighbors:\n",
    "                if speaker in memory:\n",
    "                    speaker_mem = memory[speaker]\n",
    "                    # 按照概率随机选择一个标签（简单起见，这里直接均匀随机选择，标准SLPA是按频率采样）\n",
    "                    label = np.random.choice(speaker_mem)\n",
    "                    spoken_labels.append(label)\n",
    "            \n",
    "            if not spoken_labels:\n",
    "                continue\n",
    "                \n",
    "            # 接受出现次数最多的标签，加入自己的内存\n",
    "            label_counts = defaultdict(int)\n",
    "            for label in spoken_labels:\n",
    "                label_counts[label] += 1\n",
    "            \n",
    "            max_freq = max(label_counts.values())\n",
    "            # 可能有多个标签频率并列第一\n",
    "            best_labels = [l for l, c in label_counts.items() if c == max_freq]\n",
    "            selected_label = np.random.choice(best_labels)\n",
    "            \n",
    "            memory[listener].append(selected_label)\n",
    "            \n",
    "    # 根据阈值生成社区标签集合\n",
    "    communities = {}\n",
    "    for node, mem in memory.items():\n",
    "        total = len(mem)\n",
    "        counts = defaultdict(int)\n",
    "        for label in mem:\n",
    "            counts[label] += 1\n",
    "        \n",
    "        # 保留出现概率 >= threshold 的标签\n",
    "        node_communities = set()\n",
    "        for label, count in counts.items():\n",
    "            if count / total >= threshold:\n",
    "                node_communities.add(label)\n",
    "        \n",
    "        communities[node] = node_communities\n",
    "                \n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "27f9f525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 45/45 [00:00<00:00, 118.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "发现的社区数量: 250\n",
      "\n",
      "社区 2 (标签: 查理·韦斯莱) 包含成员:\n",
      " - 查德里火炮队\n",
      " - 布斯巴顿魔法学院\n",
      " - 魔法生物管理控制司 (曾经)\n",
      " - 《预言家日报》魁地奇资深记者\n",
      " - 亚瑟·韦斯莱\n",
      " - 伊万斯姐妹的父亲\n",
      " - 泰丝\n",
      " - 莫丽·普威特\n",
      " - 古灵阁巫师银行\n",
      " - 乔艾·詹肯斯\n",
      " - 禁止滥用麻瓜物品办公室主任\n",
      " - 哈德温·波特\n",
      " - 费比安·普威特\n",
      " - 弗雷德·韦斯莱\n",
      " - 赫敏·格兰杰\n",
      " - 罗恩·韦斯莱\n",
      " - 珀克斯家族\n",
      " - 赫敏·韦斯莱\n",
      " - 拉环\n",
      " - 威森加摩成员 (1612年-1652年)\n",
      " - 莉莉·伊万斯\n",
      " - 先遣警卫\n",
      " - 伊格内修斯·普威特\n",
      " - 雨果·韦斯莱\n",
      " - 路易·韦斯莱\n",
      " - 佩弗利尔\n",
      " - 他的同伙\n",
      " - 德思礼夫人\n",
      " - 麦金农家庭\n",
      " - 阿不思·波特\n",
      " - 哈利·波特\n",
      " - 凤凰社\n",
      " - 在古灵阁巫师银行的兼职\n",
      " - 莉莉·波特\n",
      " - 德拉戈米尔·高尔格维奇\n",
      " - 乔治·韦斯莱\n",
      " - 珀西·韦斯莱\n",
      " - 伊万斯家庭\n",
      " - 查德里火炮队追球手\n",
      " - 格兰芬多学院\n",
      " - 弗雷德·韦斯莱二世\n",
      " - 波特夫人\n",
      " - 比尔·韦斯莱\n",
      " - 弗利蒙家族\n",
      " - 普威特先生\n",
      " - 波特家族\n",
      " - 弗利蒙·波特\n",
      " - 禁止滥用麻瓜物品办公室\n",
      " - 卢克丽霞·布莱克\n",
      " - 罗克珊·韦斯莱\n",
      " - 死亡圣器\n",
      " - 查理·韦斯莱\n",
      " - 弗农·德思礼\n",
      " - 佩弗利尔家族\n",
      " - 劫盗者\n",
      " - 奥黛丽·韦斯莱\n",
      " - 黑魔法防御术兼职讲师\n",
      " - 韦斯莱魔法把戏坊\n",
      " - 尤菲米娅·波特\n",
      " - 麦克米兰家族\n",
      " - 阿波琳·德拉库尔\n",
      " - 塞德瑞拉·布莱克\n",
      " - 伪劣防御咒及防护用品侦查收缴办公室\n",
      " - 格朗宁公司主管\n",
      " - 厄尼·麦克米兰\n",
      " - 斯廷奇库姆的林弗雷德\n",
      " - 韦斯莱家的孩子\n",
      " - 亨利·波特的母亲\n",
      " - 莉莉·卢娜·波特\n",
      " - 魔法法律执行司副司长\n",
      " - 梅林达·波宾\n",
      " - 詹姆·波特\n",
      " - 梅拉尼娅·麦克米兰\n",
      " - 莫丽·韦斯莱\n",
      " - 格朗宁公司\n",
      " - 罗丝·韦斯莱\n",
      " - 傲罗 (退休)\n",
      " - 阿拉斯托·穆迪\n",
      " - 古灵阁巫师银行雇员 (曾经)\n",
      " - 安德鲁·柯克\n",
      " - 格兰莫·珀克斯\n",
      " - 哈维·瑞吉比特\n",
      " - 佩妮·德思礼\n",
      " - 牛头犬饲养员\n",
      " - 路易斯·韦斯莱\n",
      " - 霍利黑德哈比队魁地奇球员\n",
      " - 吉米·珀克斯\n",
      " - 格朗宁公司的上班族 (曾经)\n",
      " - 罗尔斯顿·波特\n",
      " - 格兰杰夫人\n",
      " - 达力的孩子\n",
      " - 亨利·波特\n",
      " - 莫莉·韦斯莱\n",
      " - 伊格诺图斯·佩弗利尔的儿子\n",
      " - 芙蓉·德拉库尔\n",
      " - 比利尔斯\n",
      " - 波特瞭望站\n",
      " - 魔法法律执行司\n",
      " - 傲罗办公室主任\n",
      " - 杰克·斯劳珀\n",
      " - 古灵阁银行解咒员\n",
      " - 罗马尼亚火龙保护区\n",
      " - 多卡斯·梅多斯\n",
      " - 德拉库尔先生\n",
      " - 德拉库尔家族\n",
      " - 伊万斯夫人\n",
      " - 维克托娃·韦斯莱\n",
      " - 韦斯莱魔法把戏坊经营者\n",
      " - 伊格诺图斯·佩弗利尔\n",
      " - 卡拉多克·迪尔伯恩\n",
      " - 格兰杰先生\n",
      " - 伪劣防御咒及防护用品侦查收缴办公室主任\n",
      " - 格兰芬多魁地奇球队\n",
      " - 金妮·韦斯莱\n",
      " - 莫丽·韦斯莱二世\n",
      " - 邓布利多军\n",
      " - 安吉利娜·约翰逊\n",
      " - 韦斯莱家族\n",
      " - 达力·德思礼\n",
      " - 家养小精灵权益促进会\n",
      " - 艾欧兰斯·佩弗利尔\n",
      " - 孔博\n",
      " - 阿不思·西弗勒斯·波特\n",
      " - 多米尼克·韦斯莱\n",
      " - 普威特家庭\n",
      " - 鼻涕虫俱乐部\n",
      " - 家庭主妇\n",
      " - 玛姬·德思礼\n",
      " - 詹姆·小天狼星·波特\n",
      " - 伊万斯先生\n",
      " - 波宾家庭\n",
      " - S.P.E.W.\n",
      " - 佩妮·伊万斯\n",
      " - 火龙学家\n",
      " - 圣芒戈\n",
      " - 吉迪翁·普威特\n",
      " - 莫丽·韦斯莱，原姓普威特\n",
      " - 塞普蒂默斯·韦斯莱\n",
      " - 穆丽尔\n",
      " - 爱米琳·万斯\n",
      " - 格兰杰家庭\n",
      " - 马琳·麦金农\n",
      " - 家养小精灵解放阵线\n",
      " - 兰斯洛特 (治疗师)\n",
      " - 赫托克·达格沃斯-格兰杰\n",
      " - 安吉利娜·约翰逊的父亲\n",
      " - 韦斯莱魔法把戏坊雇员\n",
      " - 本吉·芬威克\n",
      " - 普威特家族\n",
      " - 查德里火炮队击球手\n",
      " - 约翰逊家庭\n",
      " - 达力·德思礼的孩子\n",
      " - 詹姆·波特一世\n",
      " - 加布丽·德拉库尔\n",
      " - 露西·韦斯莱\n",
      " - 斯梅廷中学\n",
      " - 德思礼家庭\n",
      " - 威森加摩成员 (1913年-1921年)\n",
      " - 安提俄克·佩弗利尔\n",
      " - 普威特夫人\n",
      " - 金妮·波特\n",
      "161\n",
      "\n",
      "社区 3 (标签: 霍格沃茨魔法学校) 包含成员:\n",
      " - 西莫·斐尼甘的父亲\n",
      " - 霍格沃茨保护神奇动物课代课教授 (早于1994年 - ?)\n",
      " - 芭斯谢达·巴布林\n",
      " - 天文学系教授(早于1991年 - ?)\n",
      " - 埃尔德·沃普尔\n",
      " - 霍格沃茨魔法学校校长\n",
      " - 洛丽丝夫人\n",
      " - 威尔克斯\n",
      " - 霍格沃茨魔法学校教师\n",
      " - 布洛贺家庭\n",
      " - 奥利夫·洪贝\n",
      " - 莉莎·杜平\n",
      " - 霍格沃茨管理员\n",
      " - 洛肯·麦克莱德\n",
      " - 布丽奇特·温洛克\n",
      " - 皮皮鬼\n",
      " - 克里瓦特家族\n",
      " - 赫奇帕奇学院幽灵\n",
      " - 韦恩·霍普金斯\n",
      " - 奥罗拉·辛尼斯塔\n",
      " - 佩内洛·克里瓦特\n",
      " - S.卡珀\n",
      " - 调查行动组\n",
      " - 莎莉安·波克斯\n",
      " - 拉文克劳学院\n",
      " - 阿格斯·费尔奇\n",
      " - 血人巴罗\n",
      " - 斯莱特林学院幽灵\n",
      " - 德里安·普塞\n",
      " - 哈罗德·丁戈\n",
      " - 菲戈\n",
      " - 蒙太家庭\n",
      " - 威尔米娜·格拉普兰\n",
      " - 天主教堂\n",
      " - 斐尼甘家庭\n",
      " - 帕翠霞·斯廷森\n",
      " - 斐尼甘夫人\n",
      " - 杰玛·法利\n",
      " - 胡珀家庭\n",
      " - 尤普拉西娅·摩尔\n",
      " - 霍格沃茨魔法学校管理员\n",
      " - 古代如尼文教授 (1993年之前－?)\n",
      " - C.沃林顿\n",
      " - 魔法部部长 (1923年－1925年)\n",
      " - 斐尼甘先生\n",
      " - 曼蒂·布洛贺\n",
      " - 肯尼思·托勒\n",
      " - 天文学家\n",
      " - 波克斯家庭\n",
      " - 杰弗里·胡珀\n",
      " - 魔法部部长 (1858年－1865年)\n",
      " - 特罗卡\n",
      " - 兰科罗斯·卡尔佩\n",
      " - 糊涂波里斯\n",
      " - 洪贝先生\n",
      " - 怪人尤里克\n",
      " - 算术占卜学家\n",
      " - 尤安·阿伯克龙比\n",
      " - 波佩图阿·范考特\n",
      " - 霍格沃茨魔法学校\n",
      " - 西莫·斐尼甘\n",
      " - 莫拉格·麦克道格\n",
      " - 德雷克\n",
      " - 胖修士\n",
      " - 杜格德·麦克费尔\n",
      " - 天文学系\n",
      " - 蒙太\n",
      "67\n",
      "\n",
      "社区 4 (标签: 伊索特·塞耶) 包含成员:\n",
      " - 玛莎·斯图尔特\n",
      " - 葛姆蕾·冈特\n",
      " - 伊尔弗莫尼魔法学校黑魔法防御术教师\n",
      " - 莫瑞根\n",
      " - 伊索特·塞耶\n",
      " - 冈特家族\n",
      " - 布特夫人\n",
      " - 威廉·塞耶\n",
      " - 艾吉尔伯特·冯塔纳\n",
      " - 詹姆·斯图尔特\n",
      " - 雷欧娜·斯图尔特\n",
      " - 布特先生\n",
      " - 霍格沃茨教授 (约10世纪)\n",
      " - 瑟达德·冯塔纳\n",
      " - 查威克·布特\n",
      " - 布特兄弟的母亲\n",
      " - 布特兄弟的父亲\n",
      " - 雇佣傲罗\n",
      " - 布特家族\n",
      " - 石匠\n",
      " - 卡德隆-布特家族\n",
      " - 伊尔弗莫尼魔法学校校长及创办者\n",
      " - 韦伯·布特\n",
      " - 雷欧娜·塞耶\n",
      " - 伊尔弗莫尼魔法学校\n",
      " - 玛莎·斯图尔特二世\n",
      " - 萨拉查·斯莱特林\n",
      " - 泰瑞·布特\n",
      " - 塞耶家族\n",
      " - 斯图尔特家族\n",
      " - 伊尔弗莫尼魔法学校校长\n",
      " - 斯莱特林家族\n",
      " - 荷西菲娜·卡德隆\n",
      "33\n",
      "\n",
      "社区 9 (标签: 英国魔法部) 包含成员:\n",
      " - 魔法部部长 (1962年－1968年)\n",
      " - 艾伯特·布特\n",
      " - 英国魔法部部长 (1726年－1733年)\n",
      " - 马法尔达·霍普柯克\n",
      " - 诺比·利奇\n",
      " - 英国魔法部部长 (1912年－1923年)\n",
      " - 魔法部部长 (1865年－1903年)\n",
      " - 魔法部部长 (1980年 - 1990年)\n",
      " - 爱洛伊丝·敏塔布\n",
      " - 达摩克利斯·罗尔\n",
      " - 珀尔修斯·帕金森\n",
      " - 魔法部部长 (1841年－1849年)\n",
      " - 英国魔法部部长 (1718年－1726年)\n",
      " - 安克谢斯·奥斯博特\n",
      " - 英国魔法部部长 (1968年－1975年)\n",
      " - 英国魔法部部长 (1752年)\n",
      " - 魔法部部长 (1827年－1835年)\n",
      " - 尤金尼娅·詹肯斯\n",
      " - 约瑟芬娜·弗林特\n",
      " - 英国魔法部部长 (1747年－1752年)\n",
      " - 哈罗德·明彻姆\n",
      " - 英国政府\n",
      " - 缄默人 (曾经)\n",
      " - 英国魔法部部长 (1975年－1980年)\n",
      " - 阿切尔·埃弗蒙德\n",
      " - 巴兹尔·弗莱克\n",
      " - 马克西米兰·克劳迪\n",
      " - 魔法部部长 (1789年－1798年)\n",
      " - 法里斯·斯帕文\n",
      " - 奥古斯特·卢克伍德\n",
      " - 威森加摩首席魔法师 (早于1707年)\n",
      " - 英国魔法部部长 (1770年－1781年)\n",
      " - 英国魔法部\n",
      " - 英国魔法部部长 (1925年－1939年)\n",
      " - 赫克托·弗利\n",
      " - 波蒂厄斯·纳奇布尔\n",
      " - 英国魔法部部长 (1855年－1858年2月17日)\n",
      " - 奥塔莱恩·甘布尔\n",
      " - 霍滕西亚·米里法特\n",
      " - 英国魔法部部长 (1819年－1827年)\n",
      " - 魔法部部长 (1707年－1718年)\n",
      " - 伊万杰琳·奥平顿\n",
      " - 魔法部部长 (1849年－1855年)\n",
      " - 尤里克·甘普\n",
      " - 普里西拉·杜邦\n",
      " - 米里森·巴格诺\n",
      " - 禁止滥用魔法办公室助理\n",
      " - 神秘事务司\n",
      " - 英国魔法部部长 (1781年－1789年)\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# 测试部分\n",
    "if  __name__ == '__main__':\n",
    "    kb = Knowledgebase(DATA_PATH)\n",
    "    all_nodes = kb.get_all_nodes()\n",
    "    community_labels = LPA(kb.graph, max_iterations=1000,all_nodes = all_nodes)\n",
    "\n",
    "    # 输出部分社区划分结果\n",
    "    from collections import defaultdict\n",
    "    communities = defaultdict(list)\n",
    "    for node, label in community_labels.items():\n",
    "        communities[label].append(node)\n",
    "\n",
    "    print(f\"\\n发现的社区数量: {len(communities)}\")\n",
    "    cnt = 0\n",
    "    # 为了展示结果，我们这里选取成员数目较多的社区进行打印\n",
    "    for i, (label, members) in enumerate(communities.items()):\n",
    "        \n",
    "        if cnt >= 4:  \n",
    "            break\n",
    "\n",
    "        if len(members) > 20:\n",
    "            print(f\"\\n社区 {i+1} (标签: {label}) 包含成员:\")\n",
    "            for member in members:\n",
    "                print(f\" - {member}\")\n",
    "            print(len(members))\n",
    "            cnt += 1\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c1747",
   "metadata": {},
   "source": [
    "### 换另一种基于贪心策略的算法：Louvain算法\n",
    "参考资料：\n",
    "- https://zhuanlan.zhihu.com/p/556291759?s_r=0\n",
    "- Google AI studio 生成的公式推导\n",
    "\n",
    "介绍： Louvain算法是一种用于社区检测的贪心优化算法，旨在最大化网络的模块度（Modularity）。模块度是衡量网络划分质量的指标，反映了网络中节点之间连接的密集程度。Louvain算法通过迭代地合并节点和社区来提高模块度，从而发现网络中的社区结构。\n",
    "\n",
    "主要步骤：\n",
    "1. **初始化**：将每个节点视为一个独立的社区。\n",
    "2. **局部优化**：对于每个节点，计算将其移动到邻居社区所带来的模块度增益。如果移动能够提高模块度，则将节点移动到该社区。重复此过程，直到没有节点能够通过移动来提高模块度。\n",
    "3. **社区合并**：将每个社区视为一个节点，构建新的网络。重复步骤2和3，直到模块度不再显著增加。\n",
    "\n",
    "Q：模块度定义公式如下：\n",
    "\n",
    "$$\n",
    "Q = \\frac{1}{2m} \\sum_{i,j} \\left[ A_{ij} - \\frac{k_i k_j}{2m} \\right] \\delta(c_i, c_j)\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $ Q $ 是模块度。\n",
    "- $ m $ 是图中的总边数。\n",
    "- $ A_{ij} $ 是节点 $ i $ 和节点 $ j $ 之间的边的权重（对于无权图，若存在边则为 1，否则为 0）。\n",
    "- $ k_i $ 和 $ k_j $ 分别是节点 $ i $ 和节点 $ j $ 的度数。\n",
    "- $ c_i $ 和 $ c_j $ 分别是节点 $ i $ 和节点 $ j $ 所属的社区。\n",
    "- $ \\delta(c_i, c_j) $ 是一个指示函数，当 $ c_i = c_j $ 时取值为 1，否则为 0，即只有当两个节点属于同一个社区时才计入计算。\n",
    "\n",
    "相较于LPA算法，Louvain算法更难理解一点。\n",
    "这里查资料详解一下Louvain算法中模块度衡量的原理，以及delta_Q公式的优化过程：\n",
    "\n",
    "(1) **核心公式**：\n",
    "  $$ P_{ij} = \\frac{k_i k_j}{2m} $$\n",
    "  该值表示在随机网络中，节点 $i$ 和节点 $j$ 之间产生连接的**期望边数**（或期望权重）。\n",
    "\n",
    "- **推导过程（直观理解）**：（考完研之后这些全忘了，所以让AI讲解了一下，但是我还是没有完全get到）\n",
    "  1.  **定义线头（Stubs）**：\n",
    "      - 网络中总共有 $m$ 条边，如果把边切断，总共有 $2m$ 个线头（Stub）。\n",
    "      - 节点 $i$ 拥有 $k_i$ 个线头，节点 $j$ 拥有 $k_j$ 个线头。\n",
    "  2.  **随机匹配概率**：\n",
    "      - 想象我们随机抓取一个线头，它属于节点 $i$ 的概率是 $\\frac{k_i}{2m}$。\n",
    "      - 再随机抓取另一个线头，它属于节点 $j$ 的概率是 $\\frac{k_j}{2m}$。\n",
    "  3.  **计算期望值**：\n",
    "      - 假设这两个选择是独立的，那么一条随机边连接 $i$ 和 $j$ 的联合概率约为 $\\frac{k_i}{2m} \\times \\frac{k_j}{2m}$。\n",
    "      - 因为网络中总共有 $2m$ 个端点（或者理解为有 $m$ 条边在寻找连接，且涉及方向性时的系数抵消），其数学期望（Expected Number of Edges）计算为：\n",
    "        $$ E_{ij} = 2m \\times \\frac{k_i}{2m} \\times \\frac{k_j}{2m} = \\frac{k_i k_j}{2m} $$\n",
    "\n",
    "- **模块度 Q 的物理含义**：\n",
    "  公式中的项 $$ A_{ij} - \\frac{k_i k_j}{2m} $$ 代表了 **“实际连接”** 与 **“随机连接”** 之间的差值：\n",
    "  - **$A_{ij}$**：节点 $i$ 和 $j$ 之间的实际边权重。\n",
    "  - **$\\frac{k_i k_j}{2m}$**：如果网络是随机连接的，它们之间理应具有的边权重。\n",
    "  \n",
    "  **结论**：如果差值为**正**，说明这两个节点之间的连接比随机猜测的要紧密得多，因此将它们划分到同一个社区是对模块度有益的。这体现了模块度的核心思想：**社区内的连接密度应显著高于随机网络的连接密度。**\n",
    "\n",
    "（2）**模块度增量 $\\Delta Q$ 的计算**：\n",
    "在Louvain算法中，当考虑将节点 $i$ 从其当前社区$A$移动到邻居社区 $C$ 时，模块度的变化 $\\Delta Q$ 可以通过以下公式计算：\n",
    "$$\n",
    "\\Delta Q = \\left[ \\frac{\\sum_{in} + k_{i,in}}{2m} - \\left( \\frac{\\sum_{tot} + k_i}{2m} \\right)^2 \\right] - \\left[ \\frac{\\sum_{in}}{2m} - \\left( \\frac{\\sum_{tot}}{2m} \\right)^2 - \\left( \\frac{k_i}{2m} \\right)^2 \\right]\n",
    "$$\n",
    "参数解释：\n",
    "- $\\sum_{in}$：社区 $C$ 内现有的边权重总和（无权图时为社区内边的数量）。\n",
    "- $\\sum_{tot}$：社区 $C$ 内所有节点的度数总和\n",
    "- $k_{i,in}$：节点 $i$ 与社区 $C$ 内节点之间的边权重总和，无权图时为节点 $i$ 与社区内节点相连边的数量。\n",
    "- $k_i$：节点 $i$ 的度数。  \n",
    "该公式衡量了将节点 $i$ 移动到社区 $C$ 后，模块度 $Q$ 的变化。通过计算 $\\Delta Q$，Louvain算法能够决定是否将节点 $i$ 移动到社区 $C$ 以最大化整体的模块度。\n",
    "\n",
    "关于这部分还有一点，可能大家会有和我一样的疑惑，就是上述公式实际上只有$Q_{gain}$部分，公式第二部中$- \\left( \\frac{k_i}{2m} \\right)^2$是$i$作为独立社区时的模块度贡献。\n",
    "那么节点离开原来社区的模块损失度为什么不计算呢？\n",
    "这是因为在Louvain算法的迭代过程中，节点 $i$ 的移动是基于当前社区划分的局部优化。也就是说，当我们计算将节点 $i$ 从其当前社区移动到邻居社区 $C$ 时，原社区的模块度是固定的，不会因为节点 $i$ 的移动而改变。因此，在计算模块度增量 $\\Delta Q$ 时，我们只需要关注节点 $i$ 移动到社区 $C$ 后对模块度的影响，而不需要考虑它离开原社区所带来的模块度损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c1fd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def louvain(kb,max_passes=1):\n",
    "    '''\n",
    "    手写Louvain算法实现社区发现\n",
    "    '''\n",
    "    # 无向图\n",
    "    undirected = kb.get_undirected_neighbors()\n",
    "    degrees = kb._compute_degrees(undirected)\n",
    "    m = sum(degrees.values()) /2  # 图中的总边数\n",
    "    \n",
    "    # 初始化每个节点为一个社区,直接用节点名作为社区标签\n",
    "    communities = {node: node for node in kb.get_all_nodes()} \n",
    "    node_list = kb.get_all_nodes() # list 类型\n",
    "\n",
    "    # 贪心算法\n",
    "    for _ in range(max_passes):\n",
    "        improved = False\n",
    "        for node in node_list:\n",
    "            \n",
    "            # 当前社区\n",
    "            current_community = communities[node]\n",
    "\n",
    "            # 计算当前节点和每个邻居社区的连接边数\n",
    "            neighbor_communities = defaultdict(int)\n",
    "            for neighbor in undirected[node]:\n",
    "                neighbor_community = communities[neighbor]\n",
    "                neighbor_communities[neighbor_community] += 1\n",
    "            \n",
    "            '''\n",
    "            neighbor_communities 结构示例:\n",
    "            {'社区A': 3,  # 当前节点与社区A有3条连接边}\n",
    "            '''\n",
    "\n",
    "            # 计算将节点移动到每个邻居社区的模块度增益\n",
    "            best_increase = 0\n",
    "            best_community = current_community\n",
    "\n",
    "            # 当前社区的度\n",
    "            # 修正：使用 .get() 方法防止 KeyError\n",
    "            # 在迭代过程中，某些节点可能被移动到了新的社区，而 degrees 字典只包含原始节点的度数\n",
    "            # 但这里的逻辑是计算社区的总度数，所以我们需要遍历所有属于该社区的节点\n",
    "            degree_current = sum(degrees.get(n, 0) for n in communities if communities[n] == current_community)\n",
    "            \n",
    "            for community, k_i_in in neighbor_communities.items():\n",
    "                if community == current_community:\n",
    "                    continue\n",
    "                \n",
    "                # 可能进入的社区的度\n",
    "                degree_community = sum(degrees.get(n, 0) for n in communities if communities[n] == community)\n",
    "                # 计算模块增益\n",
    "                delta_Q = (k_i_in / (2 * m))- (degrees[node] * degree_community) / (2 * m * m)\n",
    "                \n",
    "                if delta_Q > best_increase:\n",
    "                    best_increase = delta_Q\n",
    "                    best_community = community\n",
    "            \n",
    "            # 如果delta_Q > 0，则将节点移动到最佳社区\n",
    "            if best_increase > 0 and best_community != current_community:\n",
    "                communities[node] = best_community\n",
    "                improved = True\n",
    "        if not improved:\n",
    "            break\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a48cd29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 45/45 [00:00<00:00, 146.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Louvain算法发现的社区数量: 276\n",
      "\n",
      "社区 1 (标签: 神秘事务司) 包含成员:\n",
      " - \n",
      " - 魔法部高级副部长 (1995年之前－1998年)\n",
      " - 马法尔达·霍普柯克\n",
      " - 魔法部官员\n",
      " - 奥福德·乌姆里奇\n",
      " - 威尔克斯\n",
      " - 斯坦·桑帕克\n",
      " - 霍格沃茨黑魔法防御术教授 (1995年－1996年)\n",
      " - 伏地魔\n",
      " - 威森加摩\n",
      " - 骑士公共汽车售票员\n",
      " - 麻瓜出身登记委员会\n",
      " - 缄默人 (曾经)\n",
      " - 高级调查官 of 霍格沃茨 (1995年－1996年)\n",
      " - 麻瓜出身登记委员会主任 (1997年－1998年)\n",
      " - 卢卡斯·巴吉沃西\n",
      " - 埃伦·克拉克内尔\n",
      " - 英国魔法部\n",
      " - 赫克托·弗利\n",
      " - 波蒂厄斯·纳奇布尔\n",
      " - 奥塔莱恩·甘布尔\n",
      " - 霍滕西亚·米里法特\n",
      " - 伊万杰琳·奥平顿\n",
      " - 魔法部部长 (1849年－1855年)\n",
      " - 拉道夫斯·莱斯特兰奇\n",
      " - 尤里克·甘普\n",
      " - 普里西拉·杜邦\n",
      " - 芬里尔·格雷伯克\n",
      " - 米里森·巴格诺\n",
      " - 禁止滥用魔法办公室助理\n",
      " - 杜格德·麦克费尔\n",
      " - 骑士公共汽车\n",
      " - 英国魔法部部长 (1781年－1789年)\n",
      "33\n",
      "\n",
      "社区 8 (标签: 梅拉尼娅·麦克米兰) 包含成员:\n",
      " - 布斯巴顿魔法学院\n",
      " - 《预言家日报》魁地奇资深记者\n",
      " - 亚瑟·韦斯莱\n",
      " - 古灵阁巫师银行\n",
      " - 禁止滥用麻瓜物品办公室主任\n",
      " - 费比安·普威特\n",
      " - 弗雷德·韦斯莱\n",
      " - 赫敏·格兰杰\n",
      " - 罗恩·韦斯莱\n",
      " - 赫敏·韦斯莱\n",
      " - 拉环\n",
      " - 伊格内修斯·普威特\n",
      " - 雨果·韦斯莱\n",
      " - 路易·韦斯莱\n",
      " - 阿不思·波特\n",
      " - 在古灵阁巫师银行的兼职\n",
      " - 普威特先生\n",
      " - 禁止滥用麻瓜物品办公室\n",
      " - 韦斯莱魔法把戏坊\n",
      " - 阿波琳·德拉库尔\n",
      " - 伪劣防御咒及防护用品侦查收缴办公室\n",
      " - 韦斯莱家的孩子\n",
      " - 莉莉·卢娜·波特\n",
      " - 魔法法律执行司副司长\n",
      " - 罗丝·韦斯莱\n",
      " - 古灵阁巫师银行雇员 (曾经)\n",
      " - 哈维·瑞吉比特\n",
      " - 霍利黑德哈比队魁地奇球员\n",
      " - 格兰杰夫人\n",
      " - 莫莉·韦斯莱\n",
      " - 波特瞭望站\n",
      " - 格兰杰先生\n",
      " - 伪劣防御咒及防护用品侦查收缴办公室主任\n",
      " - 家养小精灵权益促进会\n",
      " - 火龙学家\n",
      " - 莫丽·韦斯莱，原姓普威特\n",
      " - 穆丽尔\n",
      " - 格兰杰家庭\n",
      " - 家养小精灵解放阵线\n",
      " - 兰斯洛特 (治疗师)\n",
      " - 赫托克·达格沃斯-格兰杰\n",
      " - 韦斯莱魔法把戏坊雇员\n",
      "42\n",
      "\n",
      "社区 12 (标签: 波特瞭望站) 包含成员:\n",
      " - 魔法生物管理控制司 (曾经)\n",
      " - 泰丝\n",
      " - 乔治·韦斯莱\n",
      " - 珀西·韦斯莱\n",
      " - 弗雷德·韦斯莱二世\n",
      " - 比尔·韦斯莱\n",
      " - 罗克珊·韦斯莱\n",
      " - 查理·韦斯莱\n",
      " - 奥黛丽·韦斯莱\n",
      " - 莫丽·韦斯莱\n",
      " - 安德鲁·柯克\n",
      " - 芙蓉·德拉库尔\n",
      " - 比利尔斯\n",
      " - 古灵阁银行解咒员\n",
      " - 罗马尼亚火龙保护区\n",
      " - 德拉库尔先生\n",
      " - 德拉库尔家族\n",
      " - 维克托娃·韦斯莱\n",
      " - 韦斯莱魔法把戏坊经营者\n",
      " - 金妮·韦斯莱\n",
      " - 莫丽·韦斯莱二世\n",
      " - 安吉利娜·约翰逊\n",
      " - 韦斯莱家族\n",
      " - 孔博\n",
      " - 阿不思·西弗勒斯·波特\n",
      " - 多米尼克·韦斯莱\n",
      " - 普威特家庭\n",
      " - 吉迪翁·普威特\n",
      " - 塞普蒂默斯·韦斯莱\n",
      " - 安吉利娜·约翰逊的父亲\n",
      " - 普威特家族\n",
      " - 约翰逊家庭\n",
      " - 加布丽·德拉库尔\n",
      " - 露西·韦斯莱\n",
      " - 普威特夫人\n",
      "35\n",
      "\n",
      "社区 21 (标签: 亨利·波特) 包含成员:\n",
      " - 伊万斯姐妹的父亲\n",
      " - 莉莉·伊万斯\n",
      " - 他的同伙\n",
      " - 哈利·波特\n",
      " - 伊万斯家庭\n",
      " - 格兰芬多学院\n",
      " - 弗利蒙·波特\n",
      " - 死亡圣器\n",
      " - 弗农·德思礼\n",
      " - 佩弗利尔家族\n",
      " - 黑魔法防御术兼职讲师\n",
      " - 尤菲米娅·波特\n",
      " - 格朗宁公司主管\n",
      " - 斯廷奇库姆的林弗雷德\n",
      " - 詹姆·波特\n",
      " - 格朗宁公司\n",
      " - 路易斯·韦斯莱\n",
      " - 吉米·珀克斯\n",
      " - 达力的孩子\n",
      " - 亨利·波特\n",
      " - 伊格诺图斯·佩弗利尔的儿子\n",
      " - 杰克·斯劳珀\n",
      " - 格兰芬多魁地奇球队\n",
      " - 艾欧兰斯·佩弗利尔\n",
      " - 玛姬·德思礼\n",
      " - 詹姆·小天狼星·波特\n",
      " - S.P.E.W.\n",
      " - 佩妮·伊万斯\n",
      " - 詹姆·波特一世\n",
      " - 威森加摩成员 (1913年-1921年)\n",
      " - 金妮·波特\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# 测试部分\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kb = Knowledgebase(DATA_PATH)\n",
    "    community_labels = louvain(kb, max_passes= 4)\n",
    "\n",
    "    # 输出部分社区划分结果\n",
    "    from collections import defaultdict\n",
    "    communities = defaultdict(list)\n",
    "    for node, label in community_labels.items():\n",
    "        communities[label].append(node)\n",
    "\n",
    "    print(f\"\\nLouvain算法发现的社区数量: {len(communities)}\")\n",
    "    cnt = 0\n",
    "    # 为了展示结果，我们这里选取成员数目较多的社区进行打印\n",
    "    for i, (label, members) in enumerate(communities.items()):\n",
    "        \n",
    "        if cnt >= 4:  \n",
    "            break\n",
    "\n",
    "        if len(members) > 20:\n",
    "            print(f\"\\n社区 {i+1} (标签: {label}) 包含成员:\")\n",
    "            for member in members:\n",
    "                print(f\" - {member}\")\n",
    "            print(len(members))\n",
    "            cnt += 1\n",
    "        else:\n",
    "            continue\n",
    "# 可视化测试\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371f469",
   "metadata": {},
   "source": [
    "利用AI生成可视化测试过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e50359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 45/45 [00:00<00:00, 152.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在生成交互式图谱: harry_potter_communities.html ...\n",
      "harry_potter_communities.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyvis.network import Network\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def visualize_communities_pyvis(kb, community_labels, output_file=\"graph_communities.html\"):\n",
    "    \"\"\"\n",
    "    使用 PyVis 生成交互式社区可视化图表\n",
    "    :param kb: Knowledgebase 对象\n",
    "    :param community_labels: 节点到社区标签的映射字典 {node: label}\n",
    "    :param output_file: 输出的 HTML 文件名\n",
    "    \"\"\"\n",
    "    # 1. 初始化 PyVis 网络\n",
    "    # height/width: 画布大小\n",
    "    # bgcolor/font_color: 背景和字体颜色\n",
    "    # notebook=True: 在 Jupyter Notebook 中显示\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", notebook=True, cdn_resources='in_line')\n",
    "    \n",
    "    # 2. 准备颜色映射\n",
    "    unique_labels = list(set(community_labels.values()))\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values()) # 使用 Matplotlib 的标准色板\n",
    "    # 循环使用颜色\n",
    "    label_to_color = {label: colors[i % len(colors)] for i, label in enumerate(unique_labels)}\n",
    "    \n",
    "    # 3. 添加节点\n",
    "    # PyVis 支持批量添加，但为了自定义颜色，我们逐个添加\n",
    "    all_nodes = kb.get_all_nodes()\n",
    "    \n",
    "    # 计算度数用于调整节点大小\n",
    "    undirected_neighbors = kb.get_undirected_neighbors()\n",
    "    degrees = {node: len(neighbors) for node, neighbors in undirected_neighbors.items()}\n",
    "    \n",
    "    for node in all_nodes:\n",
    "        community = community_labels.get(node)\n",
    "        color = label_to_color.get(community, \"#ffffff\")\n",
    "        size = degrees.get(node, 1) * 2 + 5 # 基础大小5，每多一个邻居+2\n",
    "        \n",
    "        # title 是鼠标悬停时显示的文本\n",
    "        title = f\"Node: {node}<br>Community: {community}<br>Degree: {degrees.get(node, 0)}\"\n",
    "        \n",
    "        net.add_node(node, label=node, title=title, color=color, size=size)\n",
    "    \n",
    "    # 4. 添加边\n",
    "    # 同样使用无向图逻辑避免重复\n",
    "    for node, neighbors in undirected_neighbors.items():\n",
    "        for neighbor in neighbors:\n",
    "            if node < neighbor:\n",
    "                net.add_edge(node, neighbor, color=\"#555555\") # 灰色边\n",
    "    \n",
    "    # 5. 设置物理引擎参数 (让图布局更自然)\n",
    "    # 修改：增大阻尼(damping)和斥力(gravity)，解决节点一直震荡碰撞的问题\n",
    "    net.barnes_hut(\n",
    "        gravity=-10000,        # 强斥力，让节点散开\n",
    "        central_gravity=0.3,\n",
    "        spring_length=200,     # 连线更长\n",
    "        spring_strength=0.01,  # 弹簧更软\n",
    "        damping=0.5,           # 高阻尼，快速停止运动\n",
    "        overlap=1              # 强制避免重叠\n",
    "    )\n",
    "    \n",
    "    # 6. 保存并显示\n",
    "    print(f\"正在生成交互式图谱: {output_file} ...\")\n",
    "    try:\n",
    "        # 在 Notebook 中显示\n",
    "        return net.show(output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"显示失败，请直接打开生成的 HTML 文件: {e}\")\n",
    "\n",
    "# --- 执行可视化 ---\n",
    "if __name__ == '__main__':\n",
    "    # 测试louvain算法\n",
    "    # if 'community_labels' not in locals():\n",
    "    #     kb = Knowledgebase(DATA_PATH)\n",
    "    #     community_labels = louvain(kb, max_passes=4)\n",
    "    \n",
    "    # 测试LPA算法\n",
    "    kb = Knowledgebase(DATA_PATH)\n",
    "    all_nodes = kb.get_all_nodes()\n",
    "    community_labels = LPA(kb.graph, max_iterations=50,all_nodes = all_nodes)\n",
    "    # 生成可视化\n",
    "    visualize_communities_pyvis(kb, community_labels, output_file=\"harry_potter_communities.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f5927",
   "metadata": {},
   "source": [
    "### 到此构建知识图谱的社区划分部分就完成了\n",
    "\n",
    "不管是LPA还是Louvain算法，最终都能得到每个节点所属的社区标签。社区划分的效果具有随机性，和初始条件和迭代顺序有关以及迭代次数有关。\n",
    "总的来说，感觉实现比较简单，**表现效果没有想象中的那么好**,虽然尝试了不同的做法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac094b1",
   "metadata": {},
   "source": [
    "### 图检索\n",
    "下面图检索主要实现两个功能：\n",
    "1. 基于贪心搜索算法,区别于普通的BFS，这里通过语义相似度计算，每次选择语意相似度最高的节点进行搜索，实现从起始节点到目标节点的路径检索功能。\n",
    "2. 基于社区划分结果，实现社区内的图检索功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ab869950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图检索 \n",
    "import heapq\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 注意 cosine_similarity 输入需要是二维数组 所以要reshape一下\n",
    "\n",
    "def retrieve_similar_nodes(kb, start_node, end_node,max_steps= 10):\n",
    "    '''\n",
    "    start_node: 起始节点\n",
    "    end_node: 目标节点\n",
    "    max_steps: 最大搜索步数\n",
    "    '''\n",
    "    if start_node not in kb.nodes or end_node not in kb.nodes:\n",
    "        print(\"起始节点或目标节点不存在于图中。\")\n",
    "        return []\n",
    "\n",
    "    # 获取终点的embedding\n",
    "    target_emb = kb.embeddings[end_node].reshape(1,-1)\n",
    "\n",
    "    # 初始化优先队列 heapq 是小顶堆，所以将相似度转为负数，相似度越高的，负数值越小，位于堆顶\n",
    "    queue = []\n",
    "\n",
    "    # 起点到终点相似度\n",
    "    start_emb = kb.embeddings[start_node].reshape(1,-1)\n",
    "    start_sim = cosine_similarity(start_emb,target_emb)[0][0]\n",
    "    heapq.heappush(queue,(-start_sim,start_node,[(None,start_node)]))\n",
    "    visited = set()\n",
    "    \n",
    "\n",
    "    # 搜索\n",
    "    while queue:\n",
    "        # 弹出当前最相似的节点\n",
    "        current_score, current_node, path = heapq.heappop(queue)\n",
    "\n",
    "        if current_node == end_node:\n",
    "            return path\n",
    "\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "\n",
    "        visited.add(current_node)\n",
    "\n",
    "        # 剪枝： 超过最大步数就停止这个分支\n",
    "        if len(path) > max_steps:\n",
    "            continue\n",
    "\n",
    "        neighbors = kb.get_neighbors(current_node)\n",
    "\n",
    "        for relation, neighbor in neighbors:\n",
    "            if neighbor not in visited:\n",
    "                # 增加对 None 的检查\n",
    "                # 某些节点可能没有 embedding (例如孤立点或未正确初始化的节点)\n",
    "                neighbor_emb_raw = kb.get_embedding(neighbor)\n",
    "                if neighbor_emb_raw is None:\n",
    "                    continue\n",
    "                    \n",
    "                neighbor_emb = neighbor_emb_raw.reshape(1,-1)\n",
    "                sim = cosine_similarity(neighbor_emb,target_emb)[0][0]\n",
    "                new_path = path + [(relation, neighbor)]\n",
    "                heapq.heappush(queue,(-sim, neighbor, new_path))\n",
    "    \n",
    "    return []  # 未找到路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "30cf66f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 路径详情:\n",
      "哈利·波特 (起点)\n",
      " --[~从属]--> 赫敏·格兰杰\n",
      " --[~母亲]--> 雨果·韦斯莱\n",
      " --[~表弟]--> 詹姆·小天狼星·波特\n",
      " --[~后裔]--> 伊格诺图斯·佩弗利尔\n",
      " --[哥哥]--> 卡德摩斯·佩弗利尔\n",
      " --[~祖先]--> 葛姆蕾·冈特\n",
      " --[祖先]--> 萨拉查·斯莱特林\n",
      " --[从属]--> 斯莱特林学院\n",
      " --[~从属]--> 蒙太\n"
     ]
    }
   ],
   "source": [
    "# 确保前面内容都跑过，后面才能直接用\n",
    "# --- 测试部分 ---\n",
    "# \n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    if 'kb' not in locals():\n",
    "        kb = Knowledgebase(DATA_PATH)\n",
    "\n",
    "    # 测试案例：寻找 \"哈利·波特\" 到 \"伏地魔\" 的关系\n",
    "    # 这是一个跨阵营的搜索，普通 BFS 搜索效率低，但语义搜索会优先找\"敌人\"或\"食死徒\"相关节点\n",
    "    start = \"哈利·波特\"\n",
    "    end = \"蒙太\"\n",
    "    \n",
    "    path = retrieve_similar_nodes(kb, start, end)\n",
    "    \n",
    "    if path:\n",
    "        print(\"\\n🔍 路径详情:\")\n",
    "        for i, (relation, node) in enumerate(path):\n",
    "            if relation:\n",
    "                print(f\" --[{relation}]--> {node}\")\n",
    "            else:\n",
    "                print(f\"{node} (起点)\")\n",
    "    else:\n",
    "        print(\"未找到路径。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfeab30",
   "metadata": {},
   "source": [
    "### 利用社区信息优化检索\n",
    "在图检索过程中，利用社区划分结果可以显著提升检索效率和准确性。具体方法如下：\n",
    "1. **社区优先搜索**：在进行路径检索时，优先在起始节点所属的社区内进行搜索。这是因为社区内的节点通常具有更高的相关性和连接密度，增加了找到目标节点的概率。\n",
    "2. **限制搜索范围**：如果目标节点的社区标签已知，可以将搜索范围限制在该社区内，减少不必要的计算和遍历。\n",
    "3. **动态调整搜索策略**： 如果在社区内未能找到目标节点，可以逐步扩大搜索范围，考虑邻近社区，以平衡搜索效率和准确性。\n",
    "\n",
    "但是这里通常做法需要提取社区的信息，比如利用LLM生成社区的描述信息，然后计算与目标节点的相似度，再指导搜索过程。这里采取了一种替代的方式，在原来的贪心策略上，将相似度评分修改为：\n",
    "$$score = \\alpha \\cdot sim(node, target) + (1 - \\alpha) \\cdot community\\_bonus）（基于社区给予奖励，参数可调整）$$\n",
    "这样加速我们搜索过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用社区信息优化检索\n",
    "# 图检索 \n",
    "import heapq\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def community_search(kb, start_node, end_node, community_labels, max_steps=20, alpha=0.6):\n",
    "    '''\n",
    "    基于社区感知的启发式搜索 (支持重叠社区)\n",
    "    :param community_labels: 节点到社区标签的映射字典。\n",
    "                             可以是 {node: label} (LPA/Louvain) \n",
    "                             也可以是 {node: {label1, label2}} (SLPA)\n",
    "    '''\n",
    "    if start_node not in kb.nodes or end_node not in kb.nodes:\n",
    "        print(\"起始节点或目标节点不存在于图中。\")\n",
    "        return []\n",
    "\n",
    "    # 辅助函数：获取节点的社区集合\n",
    "    def get_comm_set(node):\n",
    "        val = community_labels.get(node)\n",
    "        if val is None:\n",
    "            return set()\n",
    "        if isinstance(val, (set, list, tuple)):\n",
    "            return set(val)\n",
    "        return {val}\n",
    "\n",
    "    # 1. 预计算目标信息\n",
    "    target_emb = kb.embeddings[end_node].reshape(1, -1)\n",
    "    target_comms = get_comm_set(end_node)\n",
    "    start_comms = get_comm_set(start_node)\n",
    "    \n",
    "\n",
    "\n",
    "    # 2. 初始化优先队列\n",
    "    queue = []\n",
    "    visited = {} \n",
    "\n",
    "    # 计算起点的初始得分\n",
    "    start_emb = kb.embeddings[start_node].reshape(1, -1)\n",
    "    sem_score = cosine_similarity(start_emb, target_emb)[0][0]\n",
    "    \n",
    "    # 社区分: 如果有共同社区，则奖励\n",
    "    has_common_comm = not start_comms.isdisjoint(target_comms)\n",
    "    comm_score = 1.0 if has_common_comm else 0.0\n",
    "    \n",
    "    final_score = alpha * sem_score + (1 - alpha) * comm_score\n",
    "    \n",
    "    heapq.heappush(queue, (-final_score, start_node, [(None, start_node)]))\n",
    "    \n",
    "    steps_count = 0\n",
    "\n",
    "    # 3. 搜索循环\n",
    "    while queue:\n",
    "        current_score, current_node, path = heapq.heappop(queue)\n",
    "        steps_count += 1\n",
    "        \n",
    "        if current_node == end_node:\n",
    "            return path\n",
    "\n",
    "        if current_node in visited and visited[current_node] <= len(path):\n",
    "            continue\n",
    "        visited[current_node] = len(path)\n",
    "\n",
    "        if len(path) > max_steps:\n",
    "            continue\n",
    "\n",
    "        neighbors = kb.get_neighbors(current_node)\n",
    "\n",
    "        for relation, neighbor in neighbors:\n",
    "            neighbor_emb_raw = kb.get_embedding(neighbor)\n",
    "            if neighbor_emb_raw is None:\n",
    "                continue\n",
    "            \n",
    "            neighbor_emb = neighbor_emb_raw.reshape(1, -1)\n",
    "            sim = cosine_similarity(neighbor_emb, target_emb)[0][0]\n",
    "            \n",
    "            # B. 计算社区奖励\n",
    "            neighbor_comms = get_comm_set(neighbor)\n",
    "            # 只要邻居所在的社区集合 与 目标社区集合 有交集，就给予奖励\n",
    "            is_in_target_comm = not neighbor_comms.isdisjoint(target_comms)\n",
    "            \n",
    "            comm_bonus = 1.0 if is_in_target_comm else 0.0\n",
    "            \n",
    "            total_score = alpha * sim + (1 - alpha) * comm_bonus\n",
    "            \n",
    "            new_path = path + [(relation, neighbor)]\n",
    "            \n",
    "            if neighbor not in visited or len(new_path) < visited[neighbor]:\n",
    "                heapq.heappush(queue, (-total_score, neighbor, new_path))\n",
    "    \n",
    "    return []  # 未找到路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d43c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SLPA (Overlapping Community Detection)...\n",
      "Debug: 起点 '哈利·波特' 社区: {'阿不思·西弗勒斯·波特'}\n",
      "Debug: 终点 '蒙太' 社区: {'蒙太', '贝拉特里克斯·莱斯特兰奇', '霍格沃茨魔法学校'}\n",
      "\n",
      "✅ 找到路径 (长度 6):\n",
      "哈利·波特 (起点, 社区: 阿不思·西弗勒斯·波特)\n",
      " --[~从属]--> 桃金娘·沃伦 (社区: 桃金娘·沃伦,霍格沃茨魔法学校)\n",
      " --[从属]--> 德拉科·马尔福 (社区: 贝拉特里克斯·莱斯特兰奇)\n",
      " --[~儿子]--> 卢修斯·马尔福 (社区: 贝拉特里克斯·莱斯特兰奇)\n",
      " --[~儿子]--> 阿布拉克萨斯·马尔福 (社区: 贝拉特里克斯·莱斯特兰奇)\n",
      " --[从属]--> 斯莱特林学院 (社区: 贝拉特里克斯·莱斯特兰奇)\n",
      " --[~从属]--> 蒙太 (社区: 蒙太,贝拉特里克斯·莱斯特兰奇,霍格沃茨魔法学校)\n"
     ]
    }
   ],
   "source": [
    "# --- 测试部分 ---\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    if 'kb' not in locals():\n",
    "        kb = Knowledgebase(DATA_PATH)\n",
    "    \n",
    "  \n",
    "    all_nodes = kb.get_all_nodes()\n",
    "    # 使用 SLPA 替代 LPA\n",
    "    community_labels = SLPA(kb.graph, T=200, threshold=0.1, all_nodes=all_nodes)\n",
    "\n",
    "    start = \"哈利·波特\"\n",
    "    end = \"蒙太\" \n",
    "    \n",
    "    path = community_search(kb, start, end, community_labels, alpha=0.6)\n",
    "    \n",
    "    if path:\n",
    "        print(f\"\\n✅ 找到路径 (长度 {len(path)-1}):\")\n",
    "        for i, (relation, node) in enumerate(path):\n",
    "            # 打印社区时处理集合\n",
    "            comms = community_labels.get(node, set())\n",
    "            comm_str = \",\".join(list(comms)) if comms else \"未知\"\n",
    "            \n",
    "            if relation:\n",
    "                print(f\" --[{relation}]--> {node} (社区: {comm_str})\")\n",
    "            else:\n",
    "                print(f\"{node} (起点, 社区: {comm_str})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HiChunk_w",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
