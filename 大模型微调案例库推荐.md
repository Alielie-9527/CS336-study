# 大模型微调学习案例库推荐 🚀

本文档整理了国内外优秀的大语言模型（LLM）微调学习案例库，涵盖各种微调技术（全量微调、LoRA、QLoRA等），适合不同水平的学习者参考。

---

## 📚 综合性微调框架

### 1. **LLaMA-Factory**
- **GitHub**: [hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
- **⭐ Stars**: 35k+
- **描述**: 国内最流行的大模型微调框架之一，支持 100+ 主流模型（LLaMA、Qwen、ChatGLM等）
- **特点**:
  - 支持全量微调、LoRA、QLoRA、DoRA 等多种微调方法
  - 提供 Web UI 界面，操作简单
  - 支持多种数据集格式
  - 完善的中文文档
- **适合**: 初学者到进阶用户，工业级应用

### 2. **Firefly（流萤）**
- **GitHub**: [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly)
- **⭐ Stars**: 5k+
- **描述**: 中文开源大模型微调训练项目
- **特点**:
  - 支持 Baichuan、Qwen、InternLM 等国产模型
  - 详细的训练流程和数据处理教程
  - 包含多个训练好的中文模型
  - 提供丰富的中文训练数据集
- **适合**: 中文 LLM 微调学习者

### 3. **FastChat**
- **GitHub**: [lm-sys/FastChat](https://github.com/lm-sys/FastChat)
- **⭐ Stars**: 36k+
- **描述**: UC Berkeley 开源的训练、服务和评估大型语言模型的开放平台
- **特点**:
  - Vicuna 模型的训练代码
  - 支持多种模型部署和服务
  - 提供评测工具 MT-Bench
- **适合**: 研究者和开发者

---

## 🔧 参数高效微调（PEFT）案例

### 4. **PEFT (Parameter-Efficient Fine-Tuning)**
- **GitHub**: [huggingface/peft](https://github.com/huggingface/peft)
- **⭐ Stars**: 16k+
- **描述**: Hugging Face 官方的参数高效微调库
- **特点**:
  - 支持 LoRA、Prefix Tuning、P-Tuning、Prompt Tuning 等
  - 与 Transformers 无缝集成
  - 丰富的示例代码
  - 官方维护，质量有保障
- **适合**: 学习各种 PEFT 技术的最佳选择

### 5. **ChatGLM-Efficient-Tuning**
- **GitHub**: [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning)
- **⭐ Stars**: 3k+
- **描述**: ChatGLM 模型的高效微调实现（LLaMA-Factory 的前身）
- **特点**:
  - 专注于 ChatGLM 系列模型
  - 支持 LoRA、QLoRA、P-Tuning v2
  - 提供完整的训练和推理流程
- **适合**: ChatGLM 模型的微调学习

---

## 🎓 教学型项目

### 6. **llm-course (LLM 大学课程)**
- **GitHub**: [mlabonne/llm-course](https://github.com/mlabonne/llm-course)
- **⭐ Stars**: 40k+
- **描述**: 完整的大语言模型学习路线图和教程
- **特点**:
  - 系统的 LLM 学习路径
  - 包含微调、量化、部署等全流程
  - 丰富的 Colab 笔记本示例
  - 理论与实践结合
- **适合**: 系统学习 LLM 的初学者

### 7. **self-llm**
- **GitHub**: [datawhalechina/self-llm](https://github.com/datawhalechina/self-llm)
- **⭐ Stars**: 9k+
- **描述**: Datawhale 开源的大模型学习教程
- **特点**:
  - 详细的中文教程
  - 涵盖多个主流开源模型的微调
  - 从入门到实战的完整案例
  - 社区活跃，持续更新
- **适合**: 中文学习者，注重实战

### 8. **llm-action**
- **GitHub**: [liguodongiot/llm-action](https://github.com/liguodongiot/llm-action)
- **⭐ Stars**: 8k+
- **描述**: 大语言模型实战教程
- **特点**:
  - 涵盖预训练、微调、推理、部署全流程
  - 详细的代码注释和原理讲解
  - 包含多个实战项目
- **适合**: 希望深入理解 LLM 原理的学习者

---

## 💡 特定技术实现

### 9. **Stanford Alpaca**
- **GitHub**: [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)
- **⭐ Stars**: 29k+
- **描述**: 斯坦福大学的指令微调项目
- **特点**:
  - Self-Instruct 方法的经典实现
  - 使用 LLaMA 进行指令微调
  - 数据生成和微调流程清晰
- **适合**: 学习指令微调（Instruction Tuning）

### 10. **QLoRA**
- **GitHub**: [artidoro/qlora](https://github.com/artidoro/qlora)
- **⭐ Stars**: 10k+
- **描述**: QLoRA 论文的官方实现
- **特点**:
  - 4-bit 量化 + LoRA 微调
  - 显著降低显存需求
  - 包含完整的训练和评估代码
- **适合**: 在有限资源下进行大模型微调

### 11. **LMFlow**
- **GitHub**: [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow)
- **⭐ Stars**: 8k+
- **描述**: 香港科技大学开源的大模型微调工具箱
- **特点**:
  - 支持多种微调策略和对齐算法
  - 提供可扩展的工具包
  - RLHF 实现
- **适合**: 研究 RLHF 和对齐技术

---

## 🌟 垂直领域微调案例

### 12. **ChatGLM-6B 医疗领域微调**
- **GitHub**: [SCIR-HI/Med-ChatGLM](https://github.com/SCIR-HI/Med-ChatGLM)
- **⭐ Stars**: 1k+
- **描述**: 基于 ChatGLM-6B 的中文医疗对话模型
- **特点**:
  - 医疗领域数据集构建
  - 领域知识注入方法
  - 完整的微调流程
- **适合**: 学习垂直领域微调

### 13. **FinGLM (金融领域)**
- **GitHub**: [MetaGLM/FinGLM](https://github.com/MetaGLM/FinGLM)
- **⭐ Stars**: 1.5k+
- **描述**: 金融领域大模型微调
- **特点**:
  - 金融问答数据集
  - 检索增强生成（RAG）
  - 金融知识库构建
- **适合**: 学习金融领域 LLM 应用

---

## 🛠️ 配套工具和资源

### 14. **Chinese-LLaMA-Alpaca**
- **GitHub**: [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
- **⭐ Stars**: 18k+
- **描述**: 中文 LLaMA & Alpaca 大模型
- **特点**:
  - 中文词表扩充和预训练
  - 指令精调数据集
  - 完整的训练和部署教程
- **适合**: 中文模型微调学习

### 15. **LLM-Tuning (DeepSpeed)**
- **GitHub**: [zejunwang1/llm_tuning](https://github.com/zejunwang1/llm_tuning)
- **描述**: 使用 DeepSpeed 进行大模型微调
- **特点**:
  - 分布式训练实现
  - DeepSpeed 优化配置
  - 多种主流模型支持
- **适合**: 学习分布式训练和 DeepSpeed

### 16. **TRL (Transformer Reinforcement Learning)**
- **GitHub**: [huggingface/trl](https://github.com/huggingface/trl)
- **⭐ Stars**: 10k+
- **描述**: Hugging Face 的强化学习微调库
- **特点**:
  - PPO、DPO 等对齐算法
  - 与 Transformers 和 PEFT 集成
  - 支持 RLHF 训练
- **适合**: 学习 RLHF 和模型对齐

---

## 📖 数据集资源

### 17. **Awesome-Chinese-LLM**
- **GitHub**: [HqWu-HITCS/Awesome-Chinese-LLM](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM)
- **⭐ Stars**: 15k+
- **描述**: 中文大模型资源汇总
- **特点**:
  - 整理了大量中文训练数据集
  - 中文开源模型列表
  - 评测基准和工具
- **适合**: 寻找中文数据集和模型

### 18. **Open-Instruction-Generalist**
- **GitHub**: [AIDC-AI/Oasst1-zh](https://github.com/AIDC-AI/Oasst1-zh)
- **描述**: 开源的中文指令数据集
- **特点**:
  - 多轮对话数据
  - 人工标注质量高
  - 适合指令微调
- **适合**: 获取高质量中文指令数据

---

## 🎯 学习路径建议

### 初学者路线
1. 从 **self-llm** 或 **llm-course** 开始学习基础知识
2. 使用 **LLaMA-Factory** 进行第一次微调实践（有 Web UI）
3. 学习 **PEFT** 库了解各种参数高效微调方法
4. 尝试 **QLoRA** 在有限资源下微调大模型

### 进阶路线
1. 深入学习 **Firefly** 或 **FastChat** 的完整训练流程
2. 研究 **Stanford Alpaca** 的 Self-Instruct 数据生成方法
3. 使用 **TRL** 学习 RLHF 和模型对齐技术
4. 探索垂直领域微调（如 Med-ChatGLM、FinGLM）

### 研究者路线
1. 阅读 **LMFlow** 了解最新的微调和对齐算法
2. 研究 **DeepSpeed** 和分布式训练优化
3. 关注 Hugging Face 的 **Transformers**、**PEFT**、**TRL** 最新进展
4. 参与开源社区贡献

---

## 💬 实用建议

1. **选择合适的起点**: 初学者建议从带 Web UI 的工具（如 LLaMA-Factory）开始
2. **硬件考虑**: 显存不足时优先选择 LoRA/QLoRA 方法
3. **数据质量**: 微调效果很大程度取决于数据质量，投入时间构建高质量数据集
4. **循序渐进**: 先用小模型（如 7B）熟悉流程，再尝试大模型
5. **社区交流**: 加入各项目的讨论区和微信群，及时解决问题

---

## 📌 持续更新

本文档会持续更新最新的优秀案例库。如果你发现好的资源，欢迎通过 Issue 或 PR 贡献！

---

**最后更新时间**: 2024-12

**欢迎 Star ⭐️ 和分享！**
